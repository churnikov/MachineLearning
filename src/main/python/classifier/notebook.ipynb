{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from parseUtils import parseDocs\n",
    "\n",
    "tagDict, tagList, textList, namesList = parseDocs()\n",
    "\n",
    "with open('stop_words.txt') as sw:\n",
    "    stop_words = [line.rstrip('\\n') for line in sw]\n",
    "\n",
    "with open('important_words.txt') as iw:\n",
    "    imp_words = {line.rstrip('\\n') for line in iw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainNum = 3684\n",
    "testNumStart = 3685\n",
    "testNumFinish = len(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "stemmer = SnowballStemmer('russian')\n",
    "tkzr = CountVectorizer().build_tokenizer()\n",
    "\n",
    "stem_tokenize = lambda tokens: [stemmer.stem(item) for item in tokens if not item.isdigit()]\n",
    "tokenize = lambda text: stem_tokenize(tkzr(text))\n",
    "\n",
    "prepoc = Pipeline([('count', CountVectorizer(tokenizer=tokenize,\n",
    "                                             max_df=0.8,\n",
    "                                             min_df=0.01,\n",
    "                                             ngram_range=(1, 2),\n",
    "                                             stop_words = stem_tokenize(stop_words))),\n",
    "                   ('tfidf', TfidfTransformer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "X_train = prepoc.fit_transform(textList)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(tagList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from parseUtils import parseDoc\n",
    "p = '/Volumes/Media/Documents/Git/MachineLearning/out/21.txt'\n",
    "tags, text = parseDoc(p)\n",
    "textList.append(text)\n",
    "X_train = prepoc.fit_transform(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import (chi2, SelectKBest)\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = Pipeline([('chi2', SelectKBest(chi2, k = 'all')),\n",
    "                ('svm', LinearSVC(random_state=0,\n",
    "                                  class_weight='balanced',\n",
    "                                  C=2.0))])\n",
    "\n",
    "classer = OneVsRestClassifier(clf, n_jobs=1).fit(X_train[:trainNum, :],\n",
    "                                                y[:trainNum, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_precision = 0.6536373507057546\n",
      "micro_precision = 0.8040816326530612\n",
      "recall = 0.7748279252704031\n",
      "F1 = 0.7891837756634953\n",
      "macro_correct = 602\n",
      "micro_correct = 788\n",
      "false_neg_tags = 229\n",
      "false_pos_tags = 192\n",
      "total_test_docs = 921\n",
      "n_of_pred_tags = 980\n",
      "n_of_relevant_tags = 1017\n"
     ]
    }
   ],
   "source": [
    "import evaluation\n",
    "out = (\"/Volumes/Media/Documents/Git/MachineLearning/src\"\n",
    "            \"/main/resources/classifierOuts/\")\n",
    "evaluation.eval(out_path = out, \n",
    "                classifier = classer, \n",
    "                mlb = mlb,\n",
    "                x_train = X_train,\n",
    "                tagList = tagList,\n",
    "                namesList = namesList).evalTrainer(testNumStart, testNumFinish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n",
      "['a', 'b']\n"
     ]
    }
   ],
   "source": [
    "l = ['a', 'b']\n",
    "for i in range(0, len(l)):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "def update_file(f, tags):\n",
    "    with open(f, 'r') as fl:\n",
    "        dom = soup(fl, 'lxml')\n",
    "        t = dom.find('tags')\n",
    "        t.clear()\n",
    "        for tag in tags:\n",
    "            ta = dom.new_tag('tag')\n",
    "            t.append(ta)\n",
    "            ta.string = tag\n",
    "        with open(f, 'w') as fll:\n",
    "            html = soup.prettify(dom)\n",
    "            fll.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perdicted = classer.predict(X_train[X_train.shape[0] - 1])\n",
    "tags_pred = list()\n",
    "for j in predicted.nonzero()[1]:\n",
    "    tags_pred.append(mlb.classes_.item(j))\n",
    "if tags_pred:\n",
    "    update_file(p, tags_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
